{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 5.6MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-20.1.1\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-49.1.0-py3-none-any.whl (789 kB)\n",
      "\u001b[K     |████████████████████████████████| 789 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 45.2.0\n",
      "    Uninstalling setuptools-45.2.0:\n",
      "      Successfully uninstalled setuptools-45.2.0\n",
      "Successfully installed setuptools-49.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 516.2 MB 5.7 kB/s  eta 0:00:01  |▍                               | 6.8 MB 5.0 MB/s eta 0:01:42     |██▋                             | 41.8 MB 5.0 MB/s eta 0:01:35     |█████▏                          | 82.8 MB 73.5 MB/s eta 0:00:06     |██████▌                         | 104.1 MB 49.3 MB/s eta 0:00:09     |████████████▋                   | 204.2 MB 47.7 MB/s eta 0:00:07     |███████████████                 | 241.2 MB 45.0 MB/s eta 0:00:07     |███████████████████████████▋    | 446.0 MB 38.6 MB/s eta 0:00:02     |█████████████████████████████   | 469.4 MB 43.2 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 35 kB/s s eta 0:00:01                   | 276 kB 33.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (1.10.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 33.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 33.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow) (49.1.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 60.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 435 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 707 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.14.1)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.4.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 61.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 59.5 MB/s eta 0:00:01\n",
      "\u001b[31mERROR: tensorflow-serving-api 1.15.0 has requirement tensorflow~=1.15.0, but you'll have tensorflow 2.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.2.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.10.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h5py, astunparse, tensorboard-plugin-wit, cachetools, pyasn1-modules, google-auth, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, gast, tensorflow-estimator, tensorflow\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.18.0 google-auth-oauthlib-0.4.1 h5py-2.10.0 oauthlib-3.1.0 pyasn1-modules-0.2.8 requests-2.24.0 requests-oauthlib-1.3.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip         # pip 19.0 or higher is required for TF 2\n",
    "!pip install --upgrade setuptools\n",
    "!pip install --user --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-25 05:53:41--  https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.14.240, 216.58.193.80, 216.58.217.48, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.14.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1248381879 (1.2G) [application/zip]\n",
      "Saving to: ‘wwm_uncased_L-24_H-1024_A-16.zip’\n",
      "\n",
      "wwm_uncased_L-24_H- 100%[===================>]   1.16G  46.5MB/s    in 20s     \n",
      "\n",
      "2020-07-25 05:54:01 (58.5 MB/s) - ‘wwm_uncased_L-24_H-1024_A-16.zip’ saved [1248381879/1248381879]\n",
      "\n",
      "Archive:  wwm_uncased_L-24_H-1024_A-16.zip\n",
      "   creating: wwm_uncased_L-24_H-1024_A-16/\n",
      "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.meta  \n",
      "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: wwm_uncased_L-24_H-1024_A-16/vocab.txt  \n",
      "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.index  \n",
      "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_config.json  \n",
      "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\n",
      "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n",
      "--2020-07-25 05:54:17--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.14.208, 172.217.14.240, 2607:f8b0:400a:809::2010, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.14.208|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407727028 (389M) [application/zip]\n",
      "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
      "\n",
      "uncased_L-12_H-768_ 100%[===================>] 388.84M  74.6MB/s    in 5.4s    \n",
      "\n",
      "2020-07-25 05:54:23 (72.6 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
      "\n",
      "Archive:  uncased_L-12_H-768_A-12.zip\n",
      "   creating: uncased_L-12_H-768_A-12/\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n",
      "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\n",
      "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n",
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.45.2-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers>=3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "\u001b[K     |████████████████████████████████| 769 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-0.0.12.tar.gz (21 kB)\n",
      "Collecting tqdm>=4.47.0\n",
      "  Downloading tqdm-4.48.0-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 8.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from simpletransformers) (1.0.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from simpletransformers) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from simpletransformers) (0.22.1)\n",
      "Collecting regex\n",
      "  Downloading regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 19.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from simpletransformers) (1.18.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from simpletransformers) (2.23.0)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.9.4-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 33.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboardx\n",
      "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 61.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading tokenizers-0.8.1-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 46.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 58.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 57.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=3.0.2->simpletransformers) (20.3)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=3.0.2->simpletransformers) (3.0.12)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from seqeval->simpletransformers) (2.3.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pandas->simpletransformers) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pandas->simpletransformers) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from scikit-learn->simpletransformers) (0.14.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->simpletransformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->simpletransformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->simpletransformers) (2020.4.5.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->simpletransformers) (2.9)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb->simpletransformers) (5.3.1)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: Click>=7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb->simpletransformers) (7.1.1)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.7-py3-none-any.whl (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 58.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb->simpletransformers) (1.14.0)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb->simpletransformers) (5.7.0)\n",
      "Requirement already satisfied: watchdog>=0.8.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb->simpletransformers) (0.10.2)\n",
      "Collecting gql==0.2.0\n",
      "  Downloading gql-0.2.0.tar.gz (18 kB)\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "  Downloading sentry_sdk-0.16.2-py2.py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 69.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboardx->simpletransformers) (3.12.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from packaging->transformers>=3.0.2->simpletransformers) (2.4.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.1.2)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval->simpletransformers) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.0.8)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from watchdog>=0.8.3->wandb->simpletransformers) (0.1.2)\n",
      "Collecting graphql-core<2,>=0.5.0\n",
      "  Downloading graphql-core-1.1.tar.gz (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers) (46.1.3.post20200330)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Using cached smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: seqeval, sacremoses, subprocess32, nvidia-ml-py3, gql, graphql-core, promise\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7423 sha256=51c09badded707d2df544bb68879dfe0f4c5b183ae8ad4c68809f91a6cf4f4ac\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/1f/1b/a6/a808a7e4d1f7584e42f5e279664cd48bf24ed8392218ce6be4\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=beb8a7c01a8946dbd8e5e07a6c54aa071a4fa6b25e71fe5903eb2e2b65a9a7fe\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6489 sha256=5036e96ecd19f0c89aa88e717571cc1b8a5cb08d99dd5315bbf389af755f589f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/44/3a/ab/102386d84fe551b6cedb628ed1e74c5f5be76af8b909aeda09\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19189 sha256=94e63b2c1c213c85521cd877f373d1bc4423c72f2a5c8355ecc0beb0769e9af7\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7f/26/a3/33f2079871e2bebb3f53a2b21c3ec64129b8efdd18a6263a52\n",
      "  Building wheel for gql (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gql: filename=gql-0.2.0-py3-none-any.whl size=7628 sha256=ea5776c32a91a0740529bd0fb2121c56eb6c1b39bf2131550a2889c2403872b6\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/33/ef/a7/f614a774441771008595df4a0ac8cdf866194d24a0e431c04b\n",
      "  Building wheel for graphql-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for graphql-core: filename=graphql_core-1.1-py3-none-any.whl size=104650 sha256=8cddf146f339ee3b8eb1391c812dd7223b85f42d620326432ec5af2671afa600\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ef/ae/d6/1dfc3868f8c53b7961af004b85c1c48c07a7d639e06c3a5b08\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21495 sha256=992e722cb518fdc2b6f56117536e4d84e32ebe374ef10f9e43646f8c274d65b4\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "Successfully built seqeval sacremoses subprocess32 nvidia-ml-py3 gql graphql-core promise\n",
      "\u001b[31mERROR: transformers 3.0.2 has requirement tokenizers==0.8.1.rc1, but you'll have tokenizers 0.8.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: sentencepiece, regex, tqdm, sacremoses, tokenizers, dataclasses, transformers, seqeval, subprocess32, docker-pycreds, nvidia-ml-py3, configparser, smmap, gitdb, GitPython, shortuuid, promise, graphql-core, gql, sentry-sdk, wandb, tensorboardx, simpletransformers\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.44.1\n",
      "    Uninstalling tqdm-4.44.1:\n",
      "      Successfully uninstalled tqdm-4.44.1\n",
      "Successfully installed GitPython-3.1.7 configparser-5.0.0 dataclasses-0.7 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 nvidia-ml-py3-7.352.0 promise-2.3 regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.91 sentry-sdk-0.16.2 seqeval-0.0.12 shortuuid-1.0.1 simpletransformers-0.45.2 smmap-3.0.4 subprocess32-3.5.4 tensorboardx-2.1 tokenizers-0.8.1 tqdm-4.48.0 transformers-3.0.2 wandb-0.9.4\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (3.0.2)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (4.48.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->transformers) (2020.4.5.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from packaging->transformers) (2.4.6)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.8.1\n",
      "    Uninstalling tokenizers-0.8.1:\n",
      "      Successfully uninstalled tokenizers-0.8.1\n",
      "Successfully installed tokenizers-0.8.1rc1\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorboardx in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (2.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboardx) (1.18.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboardx) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboardx) (3.12.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardx) (46.1.3.post20200330)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting ktrain\n",
      "  Downloading ktrain-0.18.5.tar.gz (25.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow==2.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (2.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (1.4.1)\n",
      "Collecting scikit-learn==0.21.3\n",
      "  Downloading scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 35.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (3.1.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (1.0.3)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-0.2.3-py3-none-any.whl (12 kB)\n",
      "Collecting keras_bert>=0.81.0\n",
      "  Downloading keras-bert-0.85.0.tar.gz (26 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (2.23.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (0.14.1)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.8.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 59.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 51.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cchardet==2.1.5\n",
      "  Downloading cchardet-2.1.5-cp36-cp36m-manylinux1_x86_64.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 63.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (2.4)\n",
      "Requirement already satisfied: bokeh in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (2.0.1)\n",
      "Requirement already satisfied: seqeval in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (0.0.12)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (20.3)\n",
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 42.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: transformers>=2.11.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (3.0.2)\n",
      "Requirement already satisfied: ipython in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ktrain) (7.13.0)\n",
      "Collecting syntok\n",
      "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[K     |████████████████████████████████| 468 kB 50.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (3.12.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.0.8)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (2.1.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.18.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.29.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.34.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (3.2.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (2.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pandas>=1.0.1->ktrain) (2019.3)\n",
      "Collecting Keras>=2.4.3\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting keras-transformer>=0.38.0\n",
      "  Downloading keras-transformer-0.38.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->ktrain) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->ktrain) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->ktrain) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->ktrain) (2020.4.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh->ktrain) (3.7.4.1)\n",
      "Requirement already satisfied: pillow>=4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh->ktrain) (7.0.0)\n",
      "Requirement already satisfied: tornado>=5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh->ktrain) (6.0.4)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh->ktrain) (2.11.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bokeh->ktrain) (5.3.1)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.22.2-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (4.48.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (0.18.2)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.2.zip (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 64.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: promise in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (19.3.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=2.11.0->ktrain) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=2.11.0->ktrain) (2020.7.14)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=2.11.0->ktrain) (0.0.43)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=2.11.0->ktrain) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=2.11.0->ktrain) (0.1.91)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from transformers>=2.11.0->ktrain) (0.8.1rc1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (46.1.3.post20200330)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (3.0.4)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (0.15.2)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from ipython->ktrain) (0.7.5)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.10.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.17.2)\n",
      "Collecting keras-pos-embd>=0.11.0\n",
      "  Downloading keras-pos-embd-0.11.0.tar.gz (5.9 kB)\n",
      "Collecting keras-multi-head>=0.27.0\n",
      "  Downloading keras-multi-head-0.27.0.tar.gz (14 kB)\n",
      "Collecting keras-layer-normalization>=0.14.0\n",
      "  Downloading keras-layer-normalization-0.14.0.tar.gz (4.3 kB)\n",
      "Collecting keras-position-wise-feed-forward>=0.6.0\n",
      "  Downloading keras-position-wise-feed-forward-0.6.0.tar.gz (4.4 kB)\n",
      "Collecting keras-embed-sim>=0.8.0\n",
      "  Downloading keras-embed-sim-0.8.0.tar.gz (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n",
      "Collecting googleapis-common-protos\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 10.2 MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from sacremoses->transformers>=2.11.0->ktrain) (7.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain) (0.1.9)\n",
      "Requirement already satisfied: ipython-genutils in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from jedi>=0.10->ipython->ktrain) (0.5.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.1.0)\n",
      "Collecting keras-self-attention==0.46.0\n",
      "  Downloading keras-self-attention-0.46.0.tar.gz (10 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (2.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\n",
      "Building wheels for collected packages: ktrain, keras-bert, langdetect, jieba, syntok, keras-transformer, dill, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.18.5-py3-none-any.whl size=25253440 sha256=71e0acaf4877326e24cd4eb034b588bdeec75581714957b8c93f658549367165\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/6d/df/c9/c706ccb0a5dfc0cc5a4a10bc0639857a549f6d5754c1316c18\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-bert: filename=keras_bert-0.85.0-py3-none-any.whl size=34302 sha256=7e1e8afd07b98051fb2337840e1aea61288a8dd6ae2d19d5eb49bde88112667e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/98/50/2c/4ed88bed775795a88bf907be450004291e2dd29cc835263572\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=d30df7b1470fc5b83b28d63dd5840fc4fb5bcd42f00730dfb3092d5a5d16bf7f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/53/88/5d/b239dc55d773b01fdd2059606b1a8f4b64548848b8f6e381c3\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=ae36618ea2db7ebc1e76a4ce33534c011d19b9719e8f4a95b5e56d75fdeabe67\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/17/a7/8b/a7e03881534e78558920ac68aaeca05180c0e2c3d11c4fce3b\n",
      "  Building wheel for syntok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20916 sha256=a0aef9bfad6f0ac35feb61d89232d6f2668a702ad053ff4588f3e86964756605\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c8/38/c7/e7ecfda67c818d8a78e91bcefd387f842a9be4f3232ed6baba\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-py3-none-any.whl size=12941 sha256=e9961e7c148d8525ff4619672344f437089165c0ff251b89c584413691119ce7\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/12/58/ef/7ca460c584d1a61db9c87ac91c92b5ce1253946de17b1c038f\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78912 sha256=95cdcc1604ecc07530fca41b3f5cb7889beb33674e26456d82d190bb14b89b9a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/02/49/cf/660924cd9bc5fcddc3a0246fe39800c83028d3ccea244de352\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-py3-none-any.whl size=7553 sha256=7d26bd4f053416f7f1792a14728873368929d33d74014c31c9a0922fe49c7ff9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/13/b1/3b/13b632f78162148b123cddad1e0e3786df45ec37cac86dd998\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-py3-none-any.whl size=15613 sha256=b3d98267d61fbaaa8ddb89d72090772c4d5ac1fcdf0652af153cb9f8ac2bb102\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5c/62/ae/d83210a242076c1841896a80b101e9b94f6dff931457150bf4\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-py3-none-any.whl size=5267 sha256=35052aea4348d35084038204ec01d10e93c2313e8ec1a4492cb9cec68a77bd69\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/60/1a/38/858ffe627cf272dc54d9863d6c5ec993f00fd28d33f7f169f8\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-py3-none-any.whl size=5623 sha256=569d3bc8226a5f5bc2af56f7dfb1dbbeadd44156671e8020bbd848625240fc81\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/75/25/c7/5a4c25eabcddaa3f108a9fe5ad8f0ad94e6566f25c391ea4f6\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-py3-none-any.whl size=4558 sha256=c957d938d46db075361326a56f27590a3b7100ee13e92e1ddd4bd0d5ba297ecf\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/f4/07/b2/2c51209420293276f4f11e61f41b2ca73c67a53e63a753444a\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-py3-none-any.whl size=17278 sha256=8eea117bf9eaa6295cfd2172cd999fbbeb0fc27bafac7a9a707239c4f3474ebe\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ec/1c/45/1d2f27e87b5dc43e41ebfa437a231a2f7cf601db35c87b2637\n",
      "Successfully built ktrain keras-bert langdetect jieba syntok keras-transformer dill keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "Installing collected packages: scikit-learn, fastprogress, Keras, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, jieba, cchardet, googleapis-common-protos, tensorflow-metadata, dill, tensorflow-datasets, syntok, whoosh, ktrain\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: Keras 2.3.0\n",
      "    Uninstalling Keras-2.3.0:\n",
      "      Successfully uninstalled Keras-2.3.0\n",
      "Successfully installed Keras-2.4.3 cchardet-2.1.5 dill-0.3.2 fastprogress-0.2.3 googleapis-common-protos-1.52.0 jieba-0.42.1 keras-bert-0.85.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.18.5 langdetect-1.0.8 scikit-learn-0.21.3 syntok-1.3.1 tensorflow-datasets-3.2.1 tensorflow-metadata-0.22.2 whoosh-2.7.4\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
    "!unzip wwm_uncased_L-24_H-1024_A-16.zip\n",
    "\n",
    "!ls wwm_uncased_L-24_H-1024_A-16\n",
    "\n",
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip uncased_L-12_H-768_A-12.zip\n",
    "\n",
    "!ls uncased_L-12_H-768_A-12\n",
    "\n",
    "!pip install simpletransformers\n",
    "!pip install transformers\n",
    "!pip install tensorboardx\n",
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert\n",
      "  Downloading bert-2.2.0.tar.gz (3.5 kB)\n",
      "Collecting erlastic\n",
      "  Downloading erlastic-2.0.0.tar.gz (6.8 kB)\n",
      "Building wheels for collected packages: bert, erlastic\n",
      "  Building wheel for bert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bert: filename=bert-2.2.0-py3-none-any.whl size=3754 sha256=74a82a3ce0ba980b25538864137c4aa491ec968f3043544800a63786034fdbca\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/cb/da/90/bc3128c1676721ede415ed707464c4ea5671ee3e292e6b5404\n",
      "  Building wheel for erlastic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for erlastic: filename=erlastic-2.0.0-py3-none-any.whl size=6787 sha256=418ef8425b7a2b7e97f3f9cd9055c0e6d47cbaf4be2249fb0c9b40c8e79759a5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/10/bb/e1/a8f26a46f7f4d9278a50c924b93a1664e95db12b0d785da5b4\n",
      "Successfully built bert erlastic\n",
      "Installing collected packages: erlastic, bert\n",
      "Successfully installed bert-2.2.0 erlastic-2.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting bert-tensorflow\n",
      "  Downloading bert_tensorflow-1.0.1-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 3.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from bert-tensorflow) (1.14.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 3.7 MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_hub) (1.18.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_hub) (3.12.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow_hub) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow_hub) (46.1.3.post20200330)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.8.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting bert-for-tf2\n",
      "  Downloading bert-for-tf2-0.14.4.tar.gz (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 2.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting py-params>=0.9.6\n",
      "  Downloading py-params-0.9.7.tar.gz (6.8 kB)\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.48.0)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-py3-none-any.whl size=30114 sha256=f8b352415a2e1cc53fe73e1d433f89266e5b1a57ae2408f463326d44d312b13e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7c/b5/ea/3e768502fa1032a6bfefcd0e7dd95e2110e026bf3c584940cd\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-params: filename=py_params-0.9.7-py3-none-any.whl size=7302 sha256=3f4732b665423caa25e26eac68d31a2d1bd128d0c12c7b665921a9bbd67fede8\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/18/e2/80/244168a554fc8469897bb86b3ea7183b56ecc92f484e67b375\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=ef0ad3197c9d1479b5c091db4ffd374310394174453d341305c5249417e0e232\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/9d/c6/c5/a3f4a618640f461130f47e76703156c13a39cc3b96b5f4f439\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bert\n",
    "!pip install bert-tensorflow\n",
    "!pip install tensorflow_hub\n",
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import bert\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "#from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import requests\n",
    "import sys\n",
    "import urllib.parse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_seq_len,cnn_filters,dropout_rate,dnn_units):\n",
    "    input_ids = keras.layers.Input(\n",
    "                                   shape=(max_seq_len, ),\n",
    "                                   dtype='int32',\n",
    "                                   name=\"input_ids\"\n",
    "                                   )\n",
    "    input_mask = keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    \n",
    "    _, bert_output = bert_layer([input_ids, input_mask, segment_ids])\n",
    "    \n",
    "    cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")(bert_output)\n",
    "    cnn_layer1 = layers.GlobalMaxPool1D()(cnn_layer1)\n",
    "    cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")(bert_output)\n",
    "    cnn_layer2 = layers.GlobalMaxPool1D()(cnn_layer2)\n",
    "    cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")(bert_output)\n",
    "    cnn_layer3 = layers.GlobalMaxPool1D()(cnn_layer3)\n",
    "\n",
    "    concatenated = tf.concat([cnn_layer1, cnn_layer2, cnn_layer3], axis=-1) # (batch_size, 3 * cnn_filters)   \n",
    "    dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")(concatenated)\n",
    "    dropout = layers.Dropout(rate=dropout_rate)(concatenated)\n",
    "       \n",
    "    last_dense = layers.Dense(units=1,activation=\"sigmoid\")(dropout)\n",
    "    \n",
    "    model = keras.Model(inputs=[input_ids,input_mask,segment_ids], outputs=last_dense)\n",
    "    \n",
    "    model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://trainedbertmodelweights/CNN_BERT_SIMILAR_TRAINABLE_V2_weights-improvement-06-0.98.hdf5\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='trainedbertmodelweights'\n",
    "data_key = 'CNN_BERT_SIMILAR_TRAINABLE_V2_weights-improvement-06-0.98.hdf5'\n",
    "weights_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "print(weights_location)\n",
    "\n",
    "local_weights_file = 'weights.hdf5'\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(bucket, data_key, local_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of English Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\",\"she's\":\"she is\",\"he's\":\"he is\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    #convert ’ to '\n",
    "    \n",
    "    sentence = sen.replace(\"’\",\"'\")\n",
    "    \n",
    "    #expand contractions \n",
    "    sentence = expand_contractions(sentence.lower())\n",
    "    # Removing punctuation\n",
    "    #sentence = re.sub('<[^>]+>',' ', sen)\n",
    "\n",
    "    # Remove punctuations and numbers and foreign characters\n",
    "    sentence = re.sub('[^a-zA-Z]',' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\",' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+',' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_obj = tf.keras.metrics.Precision()\n",
    "recall_obj = tf.keras.metrics.Recall()\n",
    "\n",
    "CNN_FILTERS = 100\n",
    "DROPOUT_RATE = 0.2\n",
    "DNN_UNITS = 256\n",
    "MAX_SEQ_LEN = 202\n",
    "model = create_model(MAX_SEQ_LEN,CNN_FILTERS,DROPOUT_RATE,DNN_UNITS)\n",
    "#load model weights\n",
    "model.load_weights(\"./weights.hdf5\")\n",
    "\n",
    "model.compile(\n",
    "               optimizer=keras.optimizers.Adam(1e-5),\n",
    "               loss='binary_crossentropy',\n",
    "               run_eagerly=True,\n",
    "               metrics=['accuracy',precision_obj,recall_obj]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_claims(claim_text):\n",
    "    claims = [preprocess_text(claim_text)]\n",
    "\n",
    "    max_seq_len=202\n",
    "    x_input,masks,segments = [], [],[]\n",
    "\n",
    "    for new_claim in claims:\n",
    "        \n",
    "        similar_claim1 = new_claim\n",
    "        similar_claim2 = new_claim\n",
    "        similar_claim3 = new_claim\n",
    "        similar_claim4 = new_claim\n",
    "        similar_claim5 = new_claim\n",
    "        similar_claim6 = new_claim\n",
    "        similar_claim7 = new_claim\n",
    "        similar_claim8 = new_claim\n",
    "        similar_claim9 = new_claim\n",
    "        try:\n",
    "            payload = {'claim': urllib.parse.quote(new_claim)}\n",
    "            r = requests.get('https://88rrgid4rl.execute-api.us-west-2.amazonaws.com/similar-claims?claim='\\\n",
    "                             +urllib.parse.quote(new_claim)\n",
    "                            )\n",
    "            results = json.loads(r.text) \n",
    "            if results.get('claim') is not None:\n",
    "                similar_claim1 = results.get(\"similar_claims\")[0]['clean_claim']\n",
    "                similar_claim2 = results.get(\"similar_claims\")[1]['clean_claim']\n",
    "                similar_claim3 = results.get(\"similar_claims\")[2]['clean_claim']\n",
    "                similar_claim4 = results.get(\"similar_claims\")[3]['clean_claim']\n",
    "                similar_claim5 = results.get(\"similar_claims\")[4]['clean_claim']\n",
    "                similar_claim6 = results.get(\"similar_claims\")[5]['clean_claim']\n",
    "                similar_claim7 = results.get(\"similar_claims\")[6]['clean_claim']\n",
    "                similar_claim8 = results.get(\"similar_claims\")[7]['clean_claim']\n",
    "                similar_claim9 = results.get(\"similar_claims\")[8]['clean_claim']\n",
    "            else: \n",
    "                #try one more time \n",
    "                payload = {'claim': urllib.parse.quote(new_claim)}\n",
    "                r = requests.get('https://88rrgid4rl.execute-api.us-west-2.amazonaws.com/similar-claims?claim='\\\n",
    "                             +urllib.parse.quote(new_claim)\n",
    "                            )\n",
    "                results = json.loads(r.text) \n",
    "                if results.get('claim') is not None:\n",
    "                    similar_claim1 = results.get(\"similar_claims\")[0]['clean_claim']\n",
    "                    similar_claim2 = results.get(\"similar_claims\")[1]['clean_claim']\n",
    "                    similar_claim3 = results.get(\"similar_claims\")[2]['clean_claim']\n",
    "                    similar_claim4 = results.get(\"similar_claims\")[3]['clean_claim']\n",
    "                    similar_claim5 = results.get(\"similar_claims\")[4]['clean_claim']\n",
    "                    similar_claim6 = results.get(\"similar_claims\")[5]['clean_claim']\n",
    "                    similar_claim7 = results.get(\"similar_claims\")[6]['clean_claim']\n",
    "                    similar_claim8 = results.get(\"similar_claims\")[7]['clean_claim']\n",
    "                    similar_claim9 = results.get(\"similar_claims\")[8]['clean_claim']\n",
    "        except:\n",
    "\n",
    "            #try once more \n",
    "            try:\n",
    "                payload = {'claim': urllib.parse.quote(new_claim)}\n",
    "                r = requests.get('https://88rrgid4rl.execute-api.us-west-2.amazonaws.com/similar-claims?claim='\\\n",
    "                                 +urllib.parse.quote(new_claim)\n",
    "                                )\n",
    "                results = json.loads(r.text) \n",
    "                if results.get('claim') is not None:\n",
    "                    similar_claim1 = results.get(\"similar_claims\")[0]['clean_claim']\n",
    "                    similar_claim2 = results.get(\"similar_claims\")[1]['clean_claim']\n",
    "                    similar_claim3 = results.get(\"similar_claims\")[2]['clean_claim']\n",
    "                    similar_claim4 = results.get(\"similar_claims\")[3]['clean_claim']\n",
    "                    similar_claim5 = results.get(\"similar_claims\")[4]['clean_claim']\n",
    "                    similar_claim6 = results.get(\"similar_claims\")[5]['clean_claim']\n",
    "                    similar_claim7 = results.get(\"similar_claims\")[6]['clean_claim']\n",
    "                    similar_claim8 = results.get(\"similar_claims\")[7]['clean_claim']\n",
    "                    similar_claim9 = results.get(\"similar_claims\")[8]['clean_claim']\n",
    "            except:\n",
    "\n",
    "                 e = sys.exc_info()[0]\n",
    "\n",
    "        \n",
    "        text = tokenizer.tokenize(new_claim)\n",
    "\n",
    "        similar_claim1 = tokenizer.tokenize(similar_claim1)\n",
    "        similar_claim2 = tokenizer.tokenize(similar_claim2)\n",
    "        similar_claim3 = tokenizer.tokenize(similar_claim3)\n",
    "        similar_claim4 = tokenizer.tokenize(similar_claim4)\n",
    "        similar_claim5 = tokenizer.tokenize(similar_claim5)\n",
    "        similar_claim6 = tokenizer.tokenize(similar_claim6)\n",
    "        similar_claim7 = tokenizer.tokenize(similar_claim7)\n",
    "        similar_claim8 = tokenizer.tokenize(similar_claim8)\n",
    "        similar_claim9 = tokenizer.tokenize(similar_claim9)\n",
    "\n",
    "        text = text[:20]\n",
    "        similar_claim1 = similar_claim1[:20]\n",
    "        similar_claim2 = similar_claim2[:20]\n",
    "        similar_claim3 = similar_claim3[:20]\n",
    "        similar_claim4 = similar_claim4[:20]\n",
    "        similar_claim5 = similar_claim5[:20]\n",
    "        similar_claim6 = similar_claim6[:20]\n",
    "        similar_claim7 = similar_claim7[:20]\n",
    "        similar_claim8 = similar_claim8[:20]\n",
    "        similar_claim9 = similar_claim9[:20]\n",
    "        input_sequence = [\"[CLS]\"] +\\\n",
    "                         text +\\\n",
    "                         similar_claim1 +\\\n",
    "                         similar_claim2 +\\\n",
    "                         similar_claim3 +\\\n",
    "                         similar_claim4 +\\\n",
    "                         similar_claim5 +\\\n",
    "                         similar_claim6 +\\\n",
    "                         similar_claim7 +\\\n",
    "                         similar_claim8 +\\\n",
    "                         similar_claim9 +\\\n",
    "                         [\"[SEP]\"]\n",
    "\n",
    "        \n",
    "        \n",
    "        pad_len = max_seq_len - len(input_sequence)\n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_seq_len\n",
    "        x_input.append(np.array(tokens))\n",
    "        masks.append(np.array(pad_masks))\n",
    "        segments.append(np.array(segment_ids))\n",
    "\n",
    "    return model.predict(x = [x_input,masks,segments])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4098307"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_claims('N-95 masks work better than cloth masks')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99617755\n"
     ]
    }
   ],
   "source": [
    "print(predict_claims(\"Washing your hands can help keep you safe from coronavirus\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00012745535"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_claims('Coronavirus will die off in the summer once it gets warmer')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.084821686"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_claims('Only certain face masks are effective and others, such as cloth masks, are not')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_claim=\"masks don't work\"\n",
    "payload = {'claim': urllib.parse.quote(new_claim)}\n",
    "r = requests.get('https://88rrgid4rl.execute-api.us-west-2.amazonaws.com/similar-claims?claim='\\\n",
    "                 +urllib.parse.quote(new_claim)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"claim\": \"masks don\\'t work\", \"sentiment\": -0.800000011920929, \"similar_claims\": [{\"claim\": \"Says only certain face masks are effective and others, such as cloth masks, are not.\", \"label\": \"false\", \"source_label\": \"false\", \"source\": \"Politifact\", \"date\": \"2020-04-02\", \"claim_source\": \"Facebook posts\", \"explanation\": \"\", \"fact_check_url\": \"https://politifact.com/factchecks/2020/may/18/facebook-posts/face-masks-including-homemade-ones-are-effective-c/\", \"clean_claim\": \"Says only certain face masks are effective and others such as cloth masks are not\", \"sentiments\": -0.5, \"cosine_dist\": 0.26709584259787456, \"sentiment_delta\": 0.30000001192092896}, {\"claim\": \"Only certain face masks are effective and others, such as cloth masks, are not.\", \"label\": \"false\", \"source_label\": \"false\", \"source\": \" PolitiFact\", \"date\": \"2020-04-02\", \"claim_source\": \" Facebook posts\", \"explanation\": \" N95 masks offer the most protection from viral particles, health officials say, but they should be reserved for health care workers who are in direct contact with infected patients. Mask effectiveness varies, but claims that cloth masks provide 0% protection aren\\\\u2019t accurate. More studies need to be done to examine variables such as the material and fit of the mask, the wearer, and the environment. Health officials largely agree that wearing any kind of face mask, coupled with social distancing and frequent hand-washing, is more protective than going unmasked.\", \"fact_check_url\": \"https://www.politifact.com/factchecks/2020/may/18/facebook-posts/face-masks-including-homemade-ones-are-effective-c/\", \"clean_claim\": \"Only certain face masks are effective and others such as cloth masks are not\", \"sentiments\": -0.30000001192092896, \"cosine_dist\": 0.277088040019528, \"sentiment_delta\": 0.5}, {\"claim\": \"Masks are useless, even harmful.\", \"label\": \"false\", \"source_label\": \"false\", \"source\": \" Teyit\", \"date\": \"2020-06-15\", \"claim_source\": \" FB\", \"explanation\": \" The protection of the mask is not only about the wearer, but the aim is to prevent the spread. In addition, it is very difficult for medical and fabric masks recommended to be used by the general population to cause carbon dioxide poisoning.\", \"fact_check_url\": \"https://teyit.org/maskenin-ise-yaramadigi-hatta-zararli-oldugu-iddiasi/\", \"clean_claim\": \"Masks are useless even harmful\", \"sentiments\": -0.699999988079071, \"cosine_dist\": 0.30562286330955, \"sentiment_delta\": 0.10000002384185791}, {\"claim\": \"CDC does not recommend wearing masks.\", \"label\": \"false\", \"source_label\": \"false\", \"source\": \" LeadStories\", \"date\": \"2020-04-29\", \"claim_source\": \" facebook\", \"explanation\": \" The CDC revised its facemask guidelines in early April after studies indicated people who lack COVID-19 symptoms might be infected and transmit the virus to others.\", \"fact_check_url\": \"https://leadstories.com/hoax-alert/2020/04/fact-check-the-cdc-does-recommend-that-people-who-are-healthy-wear-facemasks.html\", \"clean_claim\": \"CDC does not recommend wearing masks\", \"sentiments\": -0.8000000119209291, \"cosine_dist\": 0.34141635888330335, \"sentiment_delta\": 1.1102230246251565e-16}, {\"claim\": \"People should NOT wear masks while exercising\", \"label\": \"true\", \"source_label\": \"\", \"source\": \"WHO\", \"date\": \"2020-07-18\", \"claim_source\": \"\", \"explanation\": \"People should NOT wear masks when exercising, as masks may reduce the ability to breathe comfortably. Sweat can make the mask become wet more quickly which makes it difficult to breathe and promotes the growth of microorganisms. The important preventive measure during exercise is to maintain physical distance of at least one meter from others.\", \"fact_check_url\": \"https://www.who.int/emergencies/diseases/novel-coronavirus-2019/advice-for-public/myth-busters\", \"clean_claim\": \"People should NOT wear masks while exercising\", \"sentiments\": -0.8000000119209291, \"cosine_dist\": 0.35467651426019653, \"sentiment_delta\": 1.1102230246251565e-16}, {\"claim\": \"Face masks always protect against coronavirus\", \"label\": \"false\", \"source_label\": \"false\", \"source\": \"medicalnewstoday.com\", \"date\": \"\", \"claim_source\": \"\", \"explanation\": \"\", \"fact_check_url\": \"https://www.medicalnewstoday.com/articles/coronavirus-myths-explored\", \"clean_claim\": \"Face masks always protect against coronavirus\", \"sentiments\": 0.8000000119209291, \"cosine_dist\": 0.35881284970251237, \"sentiment_delta\": 1.600000023841858}, {\"claim\": \"The use of masks for COVID-19 causes hypoxia.\", \"label\": \"false\", \"source_label\": \"false\", \"source\": \" Verificado\", \"date\": \"2020-06-01\", \"claim_source\": \" Whatsapp\", \"explanation\": \" Edgar Gonz\\\\u00e1lez Barreno, academic coordinator of the Community Medicine Program at the Rafael Land\\\\u00edvar University and master in Public Health and Epidemiology interviewed by F\\\\u00e1ctica, assured that a mask could not generate hypoxia in a person.\", \"fact_check_url\": \"https://verificado.com.mx/falso-que-el-uso-de-mascarillas-pueda-producir-hipoxia/\", \"clean_claim\": \"The use of masks for COVID19 causes hypoxia\", \"sentiments\": -0.4000000059604645, \"cosine_dist\": 0.3891915805723214, \"sentiment_delta\": 0.4000000059604645}, {\"claim\": \"Prolonged use of face masks causes hypoxia.\", \"label\": \"false\", \"source_label\": \"false\", \"source\": \" Colombiacheck\", \"date\": \"2020-05-07\", \"claim_source\": \" Facebook, Twitter, Instragram, Whatsapp\", \"explanation\": \" Surgical, fabric and N95 face masks allow carbon dioxide to pass through. Misusing this implement can increase the chances of contagion.\", \"fact_check_url\": \"https://colombiacheck.com/chequeos/no-el-uso-prolongado-del-tapabocas-no-produce-hipoxia\", \"clean_claim\": \"Prolonged use of face masks causes hypoxia\", \"sentiments\": -0.699999988079071, \"cosine_dist\": 0.3892177522685113, \"sentiment_delta\": 0.10000002384185791}, {\"claim\": \"N95 masks -- considered to be the best respirator masks-- are in short supply worldwide .\", \"label\": \"true\", \"source_label\": \"true news\", \"source\": \"webmd.com\", \"date\": \"\", \"claim_source\": \"https://www.webmd.com/lung/news/20200403/scammers-taking-advantage-of-n95-mask-shortage\", \"explanation\": \"\", \"fact_check_url\": \"webmd.com\", \"clean_claim\": \"N95 masks considered to be the best respirator masks are in short supply worldwide\", \"sentiments\": 0.30000001192092896, \"cosine_dist\": 0.3892954594538963, \"sentiment_delta\": 1.100000023841858}, {\"claim\": \"My mask will keep someone else safe and their mask will keep me safe.\", \"label\": \"true\", \"source_label\": \"true\", \"source\": \"Politifact\", \"date\": \"2020-03-28\", \"claim_source\": \"Pat Toomey\", \"explanation\": \"\", \"fact_check_url\": \"https://politifact.com/factchecks/2020/apr/01/pat-toomey/will-homemade-masks-stop-coronavirus-spreading-fac/\", \"clean_claim\": \"My mask will keep someone else safe and their mask will keep me safe\", \"sentiments\": 0.699999988079071, \"cosine_dist\": 0.39296596391080874, \"sentiment_delta\": 1.5}]}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
