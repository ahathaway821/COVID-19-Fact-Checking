{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /anaconda3/lib/python3.7/site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (2.0.1)\n",
      "Requirement already satisfied: soupsieve in /anaconda3/lib/python3.7/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install soupsieve\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datecheckedlist = []\n",
    "country1list = []\n",
    "country2list = []\n",
    "country3list = []\n",
    "country4list = []\n",
    "countrieslist = []\n",
    "Organizationlist = []\n",
    "claimlist = []\n",
    "finalratinglist = []\n",
    "sourcelist = []\n",
    "explanationlist = []\n",
    "factCheckLinklist = []\n",
    "for i in range(1,440):\n",
    "    url = 'https://www.poynter.org/ifcn-covid-19-misinformation/page/'+str(i)+'/'\n",
    "    req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "    webpage = urlopen(req).read()\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    aref = soup.find_all('a',href=True,attrs={'class':'button entry-content__button entry-content__button--smaller'})\n",
    "    for ref in aref[:]:\n",
    "        innerurl = ref['href']\n",
    "        innerreq = Request(innerurl , headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        innerwebpage = urlopen(innerreq).read()\n",
    "        innersoup = BeautifulSoup(innerwebpage, 'html.parser')\n",
    "        innerdiv = innersoup.find_all('div',attrs={'class':'post-container'})\n",
    "        date_country = innerdiv[0].find('strong').text\n",
    "        datechecked = date_country.split('|')[0]\n",
    "        country1 = str(date_country.split('|')[1].split(',')[0:1]).strip(\"[]'\")\n",
    "        country2 = str(date_country.split('|')[1].split(',')[1:2]).strip(\"[]'\")\n",
    "        country3 = str(date_country.split('|')[1].split(',')[2:3]).strip(\"[]'\")\n",
    "        country4 = str(date_country.split('|')[1].split(',')[3:4]).strip(\"[]'\")\n",
    "        countries = date_country.split('|')[1]\n",
    "        Organization = str(innerdiv[0].find('p',attrs={'class':'entry-content__text entry-content__text--org'})\\\n",
    "                       .text.split(':')[1:2]).strip(\"[]'\")\n",
    "        claim = str(innerdiv[0].find('h1',attrs={'class':'entry-title'}).text.split(':')[1:2]).strip(\"[]'\\\\t\")\n",
    "        finalrating = str(innerdiv[0].find('h1',attrs={'class':'entry-title'}).text.split(':')[0:1]).strip(\"[]'\\\\n\\\\t\")\n",
    "        source = str(innerdiv[0].find('p',attrs={'class':'entry-content__text entry-content__text--smaller'}).text\\\n",
    "                 .split(':')[1:2]).strip(\"[]'\\\\n\")\n",
    "        explanation = str(innerdiv[0].find('p',attrs={'class':'entry-content__text entry-content__text--explanation'})\\\n",
    "                          .text.split(':')[1:2]).strip(\"[]'\\\\n\")\n",
    "        factCheckLink = innerdiv[0].find('a',attrs={'class':'button entry-content__button entry-content__button--smaller'})\\\n",
    "                        ['href']\n",
    "        datecheckedlist.append(datechecked)\n",
    "        country1list.append(country1)\n",
    "        country2list.append(country2)\n",
    "        country3list.append(country3)\n",
    "        country4list.append(country4)\n",
    "        countrieslist.append(countries)\n",
    "        Organizationlist.append(Organization)\n",
    "        claimlist.append(claim)\n",
    "        finalratinglist.append(finalrating)\n",
    "        sourcelist.append(source)\n",
    "        explanationlist.append(explanation)\n",
    "        factCheckLinklist.append(factCheckLink)\n",
    "        \n",
    "        #print(claim)\n",
    "        #print(explanation)\n",
    "        #print(innerdiv[0])\n",
    "        #label = i.find('span',attrs={'class':'entry-title--red'})\n",
    "        #text = i\n",
    "df = pd.DataFrame({'When did you see the claim?':datecheckedlist,\n",
    "                   'Country 1':country1list,\n",
    "                   'Country 2':country2list,\n",
    "                   'Country 3':country3list,\n",
    "                   'Country 4':country4list,\n",
    "                   'Countries':countrieslist,\n",
    "                   'Organization':Organizationlist,\n",
    "                   'What did you fact-check?':claimlist,\n",
    "                   'Who said/posted it?':sourcelist,\n",
    "                   #'Link to the original piece':,\n",
    "                   'URL to fact-checked article (in your language)':factCheckLinklist,\n",
    "                   #'Language of your fact-check':,\n",
    "                   'Final rating':finalratinglist,\n",
    "                   'Explanation':explanationlist\n",
    "                   #'Category':\n",
    "                   }) \n",
    "df.to_csv('poynterDataScraped27May2020.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
